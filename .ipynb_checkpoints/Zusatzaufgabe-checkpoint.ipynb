{"cells":[{"cell_type":"markdown","metadata":{},"source":["# *Number prediction* auf Basis von k-nearest neighbors\n","> FD II - Introduction to Machine Learning (5. Sem., 3. Woche | ZHAW)\n","\n","In dieser Lektion möchten wir:\n","* Die Schritte im Modellierungsprozess durchspielen und verstehen \n","* Ziffern (0-9) anhand von Bildern erkennen mit der Hilfe von...\n","* ...k-NN, das wir als Modell kennen lernen\n","\n","*Hinweis:* kaggle Notebook zum Nachlesen im Anschluss / Lektions-Unterlagen zur Verfügung."]},{"cell_type":"markdown","metadata":{},"source":["### Tool\n","--> Jupyter Notebook / kaggle Notebook"]},{"cell_type":"markdown","metadata":{},"source":["<table>\n","  <tr>\n","    <th><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/1200px-Jupyter_logo.svg.png\" width=160 /></th>\n","    <th><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p></th>\n","    <th><img src=\"https://miro.medium.com/max/668/1*GZrTyTz0OKMbxnO5Trhcew.png\" width=160 /></th>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["### Use Case: Post Briefzentrum\n","Maschinelle Erkennung von Anschriften - wie geschieht das? \n","<table>\n","  <tr>\n","    <th><center>Ausnahmefälle von Briefen, die manuell sortiert werden</center><img src=\"https://www.post.ch/-/media/portal-opp/corona/corona-story-eclepens.jpg?mw=1200&vs=2&hash=DBBD6DB3CA2837A07C4A1391F7191FB4\" width=600 /></th>\n","    <th><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p></th>\n","    <th><center>Eine Adresse die es zu interpretieren gilt</center><img src=\"https://handgeschrieben.ch/wp-content/uploads/2020/05/Bilder_Sophie_Carl-e1589809613377.jpg\" width=450 /></th>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1 - Daten | MNIST"]},{"cell_type":"markdown","metadata":{},"source":["Der MNIST-Datensatz ist ein bekannter Datensatz, der aus **28x28 Graustufenbildern mit je einer Zahl** besteht. Es enthält eine Trainingsmenge von 60.000 samples und eine Testmenge von 10.000 samples.\n","Für jedes Bild kennen wir die entsprechenden Ziffern, d.h. Labels (von 0 bis 9).\n","\n","MNIST in all seiner Schönheit:\n","![MNIST in all seiner Schönheit](https://miro.medium.com/max/800/1*LyRlX__08q40UJohhJG9Ow.png)\n","> MNIST (Modified National Institute of Standards and Technology database) ist hier verfügbar: http://yann.lecun.com/exdb/mnist/index.html"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2 - Modellwahl | k-Nearest Neighbor"]},{"cell_type":"markdown","metadata":{},"source":["k-NN ist ein **Classifier**, der auf Basis \"gelernter\" Daten neue Daten klassifiziert. Dies ist ein sehr grundlegendes, einfaches Modell, das oft als \"baseline\" zum Vergleich genutzt wird.\n","\n","Zum Zeitpunkt der Prediction wird das **Label (d.h. die Klasse, also das Resultat der Klassifizierung)** auf Basis der \"k nearest neighbors\" zum Testpunkt ausgewählt. Die Zahl `k` wird dabei zu Beginn definiert.\n","\n","Hier ein Beispiel für `k = 3`:\n","![Example k-nn with k=3](https://lazyprogrammer.me/wp-content/uploads/2015/03/main-qimg-9574c0ddd16bd6eb1ff291f0c0f3be5d-300x185.png)\n","\n","**--> Frage:** wie würde der Punkt klassifiziert werden?"]},{"cell_type":"markdown","metadata":{},"source":["Wir zählen für `k = 3` die drei \"geometrisch\" nächsten Nachbarn und zählen ihre *Votes* zusammen um auf das Resultat (hier: weiss) zu kommen.\n","\n","Hier ein weiteres Beispiel, in dem es abhängt was wir für `k` auswählen:\n","![k-nn example with k=3/5](https://lazyprogrammer.me/wp-content/uploads/2015/03/0_zbaCKocplWAbM1m5-238x300.png)\n","\n","**Die Idee ist, dass die Daten im \"Raum\" geclustert sein sollten. Punkte aus der gleichen Klasse sollten nahe beieinander liegen.** Tatsächlich ist dies eine Idee, die für nahezu alle Algorithmen in Machine Learning gilt!\n","\n","Wenn Datenpunkte, die nahe beieinander liegen, der gleichen Klasse angehören, dann folgt daraus, dass ein Testpunkt klassifiziert werden kann, indem man sich die Klassen seiner Nachbarn ansieht.\n","\n","k-NN baut im Vergleich zu anderen Ansätzen **nicht per se ein probabilistisches Modell** auf, sondern speichert nur die Trainings-Daten `X_train` und `y_train` ab. Es wird also nicht \"gelernt\"."]},{"cell_type":"markdown","metadata":{},"source":["## Step 3 - Umgebung vorbereiten | Daten laden und vorbereiten"]},{"cell_type":"markdown","metadata":{},"source":["### Umgebung vorbereiten\n","Wir beginnen, wie immer, mit dem **Import der wichtigsten Module** / Packages, die uns die Funktionalitäten bieten, die wir benötigen."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os # manipulate files\n","import cv2 # opencv image processing\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # plotting library\n","from random import randint # getting random integers\n","\n","# ML models and metrics\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# the MNIST dataset\n","from keras.datasets import mnist\n","\n","print('Modules loaded.')"]},{"cell_type":"markdown","metadata":{},"source":["Und wir definieren noch ein paar Funktionen die uns später etwas Arbeit abnehmen."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_data_subset(array : np.ndarray, quantifier : float) -> np.ndarray:\n","    \"\"\"Splits an array based on a quantifier, e.g. 0.1 for 10% of the data.\"\"\"\n","    array = (np.split(array, 1 / data_quant))[0]\n","    return array\n","\n","\n","def plot_samples(samples : np.ndarray, titles : list, figsize=(3,3)):\n","    \"\"\"Helper function for plotting samples.\"\"\"\n","    sample_count = samples.shape[0] % (28 * 28 - 1) # corrected for single sample\n","    if len(titles) != sample_count: # check arguments\n","        raise ValueError('Count of {} samples and {} labels do not match.'. format(sample_count, len(titles)))\n","    if sample_count <= 15: # find right subplot layout\n","        plot_layout = [1, sample_count]\n","    elif sample_count % 15 == 0:\n","        plot_layout = [int(sample_count/15), 15]\n","    else:\n","        plot_layout = [1 + int(sample_count/15), int((sample_count + 1)/2)]\n","\n","    # set up subplots\n","    fig, axs = plt.subplots(*plot_layout, figsize=figsize)\n","    fig.tight_layout()\n","    \n","    # plot\n","    if sample_count == 1:\n","        axs.axis('off')\n","        axs.set_title(titles[0])\n","        axs.imshow(samples.reshape(28,28), cmap='Greys')\n","        return\n","    \n","    for idx, ax in enumerate(axs.flatten()):\n","        ax.axis('off')\n","        if idx == sample_count:\n","            break #stop when we plotted everything\n","        ax.set_title(titles[idx])\n","        ax.imshow(samples[idx].reshape(28,28), cmap='Greys')\n","\n","\n","print('Functions {} defined.'.format(', '.join([get_data_subset.__name__, plot_samples.__name__])))"]},{"cell_type":"markdown","metadata":{},"source":["### Daten laden\n","Wie bereits erwähnt, ist der Hauptaufwand bei der Aufbereitung der Daten sodass das ausgewählte Modell sie richtig verwerten kann. Wir machen dazu die kommenden Schritte:\n","* Daten laden\n","* Einen Teil der Daten ignorieren (nur für dieses Beispiel, für Geschwindigkeit)\n","* Daten umformen auf 2D, da die Modelle keine 3D Daten akzeptieren"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print('\\nLoaded data - there are \\33[34m{}\\033[0m data points for training and \\33[34m{}\\033[0m for testing.'.format(X_train.shape[0], X_test.shape[0]))\n","\n","data_quant = 0.1 # only take a certain amount of data (speed)\n","print('\\nLet''s only keep \\33[34m{}%\\033[0m of that data. As we don\\'t want to wait...'.format(data_quant * 100))\n","\n","X_train = get_data_subset(X_train, data_quant)\n","y_train = get_data_subset(y_train, data_quant)\n","X_test = get_data_subset(X_test, data_quant)\n","y_test = get_data_subset(y_test, data_quant)\n","print('Ok, now we have \\33[34m{}\\033[0m data points for training and \\33[34m{}\\033[0m for testing.'.format(X_train.shape[0], X_test.shape[0]))"]},{"cell_type":"markdown","metadata":{},"source":["**Wiederholung: Aufteilung der Daten**\n","\n","Wie bereits besprochen, werden im Machine Learning die zur Verfügung stehenden Daten immer aufgeteilt:\n","<table>\n","  <tr>\n","    <th><center>High-Level Nutzung der Daten</center><br/><img src=\"https://miro.medium.com/max/656/0*FKrWuLRbB_MiEIKh\" width=400 /></th>\n","    <th><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p></th>\n","    <th><center>Aufteilung der Datensätze</center><br/><img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543836883/image_6_cfpjpr.png\" width=600 /></th>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["### Daten vorbereiten"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["# reshape data\n","print('We have a shape that looks like \\33[34m{}\\033[0m for training and \\33[34m{}\\033[0m for testing.'.format(X_train.shape, X_test.shape))\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n","print('Now it\\'s \\33[34m{}\\033[0m for training and \\33[34m{}\\033[0m for testing.'.format(X_train.shape, X_test.shape))"]},{"cell_type":"markdown","metadata":{},"source":["Jetzt können wir einen Blick auf solch ein Sample (d.h. ein Daten-Punkt) werfen."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot an image of a random sample\n","show = randint(0, X_train.shape[0]) # get a random item to show\n","plt.imshow(X_train[show].reshape(28, 28), cmap='Greys')\n","plt.title(f'label: {y_train[show]}')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4 - Modell erstellen und trainieren | k-NN model\n","Jetzt wo die Daten bereitstehen, können wir das k-NN Modell erstellen und trainieren."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["# create the k-NN model\n","k = 5 # the model will decide based on the 5 nearest neighbors\n","knn = KNeighborsClassifier(n_neighbors=k) # create model\n","knn.fit(X_train, y_train) # train model\n","print('Trained the model for \\33[34m{}\\033[0m neighbors, based on training data.'.format(k))"]},{"cell_type":"markdown","metadata":{},"source":["In diesem Beispiel (k-NN) ist das erstellen und trainieren sehr einfach. Bei komplexeren Modellen wird viel Aufwand benötigt um die richtigen Parameter zu finden."]},{"cell_type":"markdown","metadata":{},"source":["## Step 5 - Modell testen und auswerten | k-NN accuracy test\n","Nun, wo wir das Modell erstellt und trainiert haben, können wir es testen und auswerten."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["print('Predicting on \\33[34m{}\\033[0m testing samples...'.format(X_test.shape[0]))\n","predicted = knn.predict(X_test)\n","expected = y_test.tolist()\n","print('Achieved an accuracy of \\33[34m{}\\033[0m.'.format(accuracy_score(expected, predicted)))"]},{"cell_type":"markdown","metadata":{},"source":["An dieser Stelle ein paar Fragen:\n","* Was genau heisst dies für das Modell?\n","* Wären mehr Daten besser gewesen?\n","* Wäre ein grösseres `k` besser gewesen?"]},{"cell_type":"markdown","metadata":{},"source":["Antworten:\n","* Relativ gutes Modell - es kommt ca. bei 9 von 10 Bildern auf das richtige Resultat - liesse sich aber noch verbessern.\n","* Mit 60k/10k Samples wurde 0.9688 (statt 0.916) accuracy erreicht.\n","* Mit `k = 9` wurde 0.906 accuracy erreicht. Für `k = 3` war es 0.913. Für `k = 5` (default) 0.916. Bei der Wahl des richtigen `k` kommt es auf die Daten an."]},{"cell_type":"markdown","metadata":{},"source":["## Step 6 - Modell analysieren und verbessern | analyze and improve\n","Als nächstes können wir uns Beispiele der Fehler anschauen."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_smpl = X_test[0:15*15] # select the samples we want to plot\n","titles = [] # generate the plot titles for these samples\n","for idx in range(0, 15*15):\n","    if predicted[idx] != y_test[idx]:\n","        titles.append('## {} ({}) ##\\nat {}'.format(predicted[idx], y_test[idx], idx))\n","    else:\n","        titles.append(y_test[idx])\n","\n","# plot the samples\n","plot_samples(plot_smpl, titles, figsize=(25,25))"]},{"cell_type":"markdown","metadata":{},"source":["Fragen:\n","* Warum geschehen solche Fehler?\n","* Warum erkennen wir als Menschen diese Fehler sozusagen \"sofort\"?"]},{"cell_type":"markdown","metadata":{},"source":["### Analyse\n","Beispiel der nearest neighbors für ein Element."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# choose a sample as error\n","error_idx = 115 # index of the sample we'll look into\n","# plot the erroneous sample\n","plot_samples(X_test[error_idx], ['## ' + str(predicted[error_idx]) + ' ('  + str(y_test[error_idx]) + ') ##'])\n","\n","# get nearest neighbors\n","X_error = X_test[error_idx].reshape(1, -1)\n","neigh = knn.kneighbors(X_error, n_neighbors=k)\n","\n","# plot neighbors\n","titles = [] # generate the plot titles for the neighbors\n","for idx in range(0, k):\n","    titles.append('label: {}\\ndist: {:.1f}'.format(y_train[neigh[1][0][idx]], neigh[0][0][idx]))\n","plot_samples(X_train[neigh[1][0]], titles, figsize=(10,10))"]},{"cell_type":"markdown","metadata":{},"source":["**Weiteres Vorgehen:**\n","\n","Auf Basis dieser Analyse könnte mit einer iterativen Verbesserung des Modells (oder der Daten) weitergefahren werden. Was wäre dabei möglich?"]},{"cell_type":"markdown","metadata":{},"source":["Mögliche Antworten:\n","* Bessere Aufbereitung der Daten (z.B. höhere Auflösung)\n","* Wahl eines anderen `k` als Modellparameter\n","* Wahl eines anderen Modells (falls es ungeeignet scheint)\n","* ..."]},{"cell_type":"markdown","metadata":{},"source":["### --- Appendix: analyse von manuell erstellten Daten-Punkten ---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import and prepare manual samples\n","samples = []\n","for dirname, _, filenames in os.walk('/kaggle/input/mnist-manual-test-data/'):\n","    for filename in filenames:\n","        print('Found sample: {}'.format(dirname + filename))\n","        im = cv2.imread(dirname + filename, cv2.IMREAD_GRAYSCALE)\n","        try:\n","            samples = np.vstack([samples, cv2.bitwise_not(im.reshape(1, -1))])\n","        except:\n","            samples = cv2.bitwise_not(im.reshape(1, -1))\n","\n","print('Found {} manual samples.'.format(samples.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# predict the manual samples\n","predicted = knn.predict(samples)\n","\n","# plot the manual samples\n","titles = [] # generate the plot titles for the samples\n","for idx in range(0, len(predicted)):\n","    titles.append('manual sample\\npredicted: {}'.format(predicted[idx]))\n","plot_samples(samples, titles, figsize=(7,7))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
